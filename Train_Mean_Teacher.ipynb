{"cells":[{"cell_type":"markdown","source":["This notebook can be used to train the mean teacher model. Please leave all parameters unchanged except for **supervised_pct**. \n","\n","Make sure to add whatever file path you think will be more convinient. In my case, for each model I created a folder, and 3 subfolders, one for the LB, UP and Mean Teacher. If you choose this method, **make sure the folders are created beforehand**. Otherwise, feel free to do whatever. For this notebook, the following things will be saved: \n","\n","1. The weights of the student model every 5 epochs (./whatever_name_you_want_epoch_X).\n","2. Running loss, supervised loss and unsupervised loss during training (every epoch).\n","3. Accuracy and IOU on train set every 5 epochs.\n","4. Accuracy and IOU on validation set every 5 epochs.\n","5. The weight profile of the unsupervised loss during training (i.e. the $\\omega$ in $L = L_{S} + \\omega_t L_U$).\n","\n","**If you use this notebook directly from colab, PLEASE make a copy and don't change anything in the original file, cuz then my kernel will crash :(**.\n","\n","NOTE: **For very low supervised percentages ($<10%$)**, the batch size might need to be increased. In that case, the wait period should also be changed. "],"metadata":{"id":"o8gFqAbtn4CK"}},{"cell_type":"code","source":["# ONLY PARAMETER THAT SHOULD BE CHANGED. \n","supervised_pct = 0.1 # what percent of training is to be labelled\n","model_save_path = \"./M10_30_03_23/M10_MT/\""],"metadata":{"id":"3s63GAbHs_xf","executionInfo":{"status":"ok","timestamp":1680204666334,"user_tz":-60,"elapsed":762,"user":{"displayName":"Giomaria Murgia","userId":"01720778101890754226"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6143,"status":"ok","timestamp":1680204674405,"user":{"displayName":"Giomaria Murgia","userId":"01720778101890754226"},"user_tz":-60},"id":"fIQq0PppFAcW","outputId":"2c099d12-b116-4e3b-aefb-61484a8c7520"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1680204674405,"user":{"displayName":"Giomaria Murgia","userId":"01720778101890754226"},"user_tz":-60},"id":"fUN1BvDDJJio","outputId":"c7589f05-1fbd-4fb7-ac80-7ce04a061552"},"outputs":[{"output_type":"stream","name":"stdout","text":["data_augmentation.py  \u001b[0m\u001b[01;34mM1_28_03_23\u001b[0m/   \u001b[01;34m__pycache__\u001b[0m/              utils.py\n","data_into_loaders.py  \u001b[01;34mM2_29_03_23\u001b[0m/   Train_Mean_Teacher.ipynb\n","\u001b[01;34mM10_30_03_23\u001b[0m/         model_UNet.py  Train_Supervised.ipynb\n"]}],"source":["%ls"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1680204674406,"user":{"displayName":"Giomaria Murgia","userId":"01720778101890754226"},"user_tz":-60},"id":"_isQRcwlFEGr","outputId":"7c1b4240-f73c-4906-aa22-cca920ef566f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Colab Notebooks/Applied DL CW\n"]}],"source":["%cd /content/gdrive/MyDrive/Colab \\Notebooks/Applied DL CW"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1680204298366,"user":{"displayName":"Giomaria Murgia","userId":"01720778101890754226"},"user_tz":-60},"id":"Klw1e4jWIg7j","outputId":"b7debd5a-27a6-40fd-9886-507a4349b6bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdata\u001b[0m/                 \u001b[01;34mM1_28_03_23\u001b[0m/   Train_Mean_Teacher.ipynb\n","data_augmentation.py  \u001b[01;34mM2_29_03_23\u001b[0m/   Train_Supervised.ipynb\n","data_into_loaders.py  model_UNet.py  utils.py\n","\u001b[01;34mM10_30_03_23\u001b[0m/         \u001b[01;34m__pycache__\u001b[0m/\n"]}],"source":["%ls"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"OldzXbtYFG7H","executionInfo":{"status":"ok","timestamp":1680204689346,"user_tz":-60,"elapsed":2,"user":{"displayName":"Giomaria Murgia","userId":"01720778101890754226"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import Adam, lr_scheduler\n","import model_UNet\n","from data_augmentation import augmentation, colorjiter, invert\n","import matplotlib.pyplot as plt\n","from data_into_loaders import get_data, download_data\n","from utils import dice_loss, wt, update_ema_variables, unsup_loss, evaluate_model"]},{"cell_type":"code","source":["download_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":117,"referenced_widgets":["489908b824c0469a814b1045fbe3171d","ea5fd48d16c744f891b74cad147d8cea","2f7fb90256384f3d8f1172d892a30c98","da4f654b720844af93a5ffda5f0f5356","6dcf94609a6443fc8f63746ed94941d0","01381922ae1742cb8974b9ee84ab9bc0","cdcba8de401248ec8517c176bd81b800","de1d885067194bdeb5481c59dc2b78a0","55f201a860b541189e579883921e69b7","4a1b2a4ae66e4c808ba8e589ff5c8230","1fdb99faf90346bdb45757c26a3c49ec","0526b58d475744d48173d80b823096e6","b50ca076dba7469fa6ea62049dd7cd10","353b848f6e844c4e912ac909efe3db64","b8242c13ae4d465ab5f7000aa1cb408e","9376170f4376498e90bdd6590ae6e70e","018297eb68d94a479560dd836a4b2adb","ccac6470651345c9ae794d6252793778","7413d91d32684b8a96943ee10a07cacc","5c4912d5a4cd4ac2931918246fbc3866","b92cb20477664400bad5580bde130c3e","c36db982e3194e1fbfb8d55929d8054f"]},"id":"2b9Nuv63AN7v","executionInfo":{"status":"ok","timestamp":1680205029029,"user_tz":-60,"elapsed":328706,"user":{"displayName":"Giomaria Murgia","userId":"01720778101890754226"}},"outputId":"eb290eaf-3cd5-4e38-cfba-e621c2623b05"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz to ./data/images.tar.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/791918971 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"489908b824c0469a814b1045fbe3171d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloading https://thor.robots.ox.ac.uk/datasets/pets/annotations.tar.gz to ./data/annotations.tar.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/19173078 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0526b58d475744d48173d80b823096e6"}},"metadata":{}}]},{"cell_type":"code","source":["# Do NOT change these hyperparams \n","img_resize = 64   \n","val_pct, test_pct = 0.2, 0.1 # Validation and test set %. \n","\n","depth, dropout_rate = 3, 0.25  # U-Net params\n","\n","# Training params\n","epochs, lr, lr_gamma = 100, 1e-3, 0.9\n","batch_size = 32\n","\n","ramp_up, consistency, wait_period = 25, 1.5, int(1000/161 * 1.1) # Teacher contribution params\n","alpha = 0.999 # Teacher update params\n","global_step = 0\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f'Using device: {device}')"],"metadata":{"id":"KbXQ-UyYEbz8","executionInfo":{"status":"ok","timestamp":1680205036997,"user_tz":-60,"elapsed":17,"user":{"displayName":"Giomaria Murgia","userId":"01720778101890754226"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ce91886c-636c-40b8-f290-80f0067392a7"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda:0\n"]}]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q7NLvKzoFAca","executionInfo":{"status":"ok","timestamp":1680205036997,"user_tz":-60,"elapsed":12,"user":{"displayName":"Giomaria Murgia","userId":"01720778101890754226"}},"outputId":"82f96097-f9c7-4175-e9ea-869713208171"},"outputs":[{"output_type":"stream","name":"stdout","text":["Adjusting learning rate of group 0 to 1.0000e-03.\n"]},{"output_type":"stream","name":"stderr","text":["/content/gdrive/MyDrive/Colab Notebooks/Applied DL CW/model_UNet.py:211: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  init.xavier_normal(m.weight)\n","/content/gdrive/MyDrive/Colab Notebooks/Applied DL CW/model_UNet.py:212: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  init.constant(m.bias, 0)\n"]}],"source":["#### Initialisation ####\n","#create 2 network\n","modelS = model_UNet.UNet(in_channels=3, num_classes=2, depth=depth)\n","modelT = model_UNet.UNet(in_channels=3, num_classes=2, depth=depth)\n","modelS,  modelT= modelS.to(device), modelT.to(device)\n","\n","#optimizer\n","optimizer = Adam(modelS.parameters(), lr=lr)\n","scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=lr_gamma, last_epoch=-1, verbose=True)"]},{"cell_type":"code","source":["mixed_train_loader, val_loader, test_loader = get_data(supervised_pct,1 - supervised_pct, val_pct, test_pct, batch_size=batch_size, img_resize=img_resize)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ioDEeRRtjYLO","executionInfo":{"status":"ok","timestamp":1680205103095,"user_tz":-60,"elapsed":66104,"user":{"displayName":"Giomaria Murgia","userId":"01720778101890754226"}},"outputId":"b8e90005-e3e9-4610-a413-330ca35aad2f"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["all images are =  7393\n"]}]},{"cell_type":"code","execution_count":42,"metadata":{"id":"cn4t1ijbFAcb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680214413405,"user_tz":-60,"elapsed":9310327,"user":{"displayName":"Giomaria Murgia","userId":"01720778101890754226"}},"outputId":"2e15963e-d39a-4aa9-a8c8-86493c2c92e5"},"outputs":[{"output_type":"stream","name":"stderr","text":["/content/gdrive/MyDrive/Colab Notebooks/Applied DL CW/utils.py:47: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1420.)\n","  ema_param.data.mul_(alpha).add_(1 - alpha, param.data)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch:    1 - Loss:  43.73, loss_sup:   43.7, loss_unsup:   21.5, w_t:  0.00\n","For training: accuracy-8%; IOU-40%\n","For validation: accuracy-76%; IOU-54%\n","Epoch:    2 - Loss:  35.76, loss_sup:   35.8, loss_unsup:   18.3, w_t:  0.00\n","Epoch:    3 - Loss:  34.11, loss_sup:   34.1, loss_unsup:   16.9, w_t:  0.00\n","Epoch:    4 - Loss:  32.33, loss_sup:   32.3, loss_unsup:   15.9, w_t:  0.00\n","Epoch:    5 - Loss:  31.84, loss_sup:   31.8, loss_unsup:   15.9, w_t:  0.00\n","Epoch:    6 - Loss:  31.72, loss_sup:   31.7, loss_unsup:   16.6, w_t:  0.00\n","For training: accuracy-8%; IOU-38%\n","For validation: accuracy-79%; IOU-59%\n","Epoch:    7 - Loss:  31.35, loss_sup:   31.2, loss_unsup:   15.9, w_t:  0.01\n","Epoch:    8 - Loss:  30.50, loss_sup:   30.3, loss_unsup:   15.6, w_t:  0.01\n","Epoch:    9 - Loss:  30.77, loss_sup:   30.4, loss_unsup:   15.4, w_t:  0.02\n","Epoch:   10 - Loss:  30.19, loss_sup:   29.7, loss_unsup:   15.5, w_t:  0.03\n","Epoch:   11 - Loss:  29.36, loss_sup:   28.7, loss_unsup:   14.8, w_t:  0.04\n","For training: accuracy-8%; IOU-39%\n","For validation: accuracy-81%; IOU-62%\n","Epoch:   12 - Loss:  29.15, loss_sup:   28.2, loss_unsup:   15.6, w_t:  0.06\n","Epoch:   13 - Loss:  30.62, loss_sup:   29.3, loss_unsup:   15.5, w_t:  0.08\n","Epoch:   14 - Loss:  29.12, loss_sup:   27.5, loss_unsup:   14.7, w_t:  0.11\n","Epoch:   15 - Loss:  30.10, loss_sup:   27.8, loss_unsup:   15.2, w_t:  0.15\n","Epoch:   16 - Loss:  31.04, loss_sup:   28.2, loss_unsup:   14.8, w_t:  0.19\n","For training: accuracy-8%; IOU-43%\n","For validation: accuracy-82%; IOU-66%\n","Epoch:   17 - Loss:  29.90, loss_sup:   26.5, loss_unsup:   13.8, w_t:  0.25\n","Epoch:   18 - Loss:  30.51, loss_sup:   26.3, loss_unsup:   13.4, w_t:  0.31\n","Epoch:   19 - Loss:  30.16, loss_sup:   25.2, loss_unsup:   12.9, w_t:  0.39\n","Epoch:   20 - Loss:  31.70, loss_sup:   25.6, loss_unsup:   12.9, w_t:  0.47\n","Epoch:   21 - Loss:  31.38, loss_sup:   24.4, loss_unsup:   12.3, w_t:  0.57\n","For training: accuracy-8%; IOU-47%\n","For validation: accuracy-83%; IOU-68%\n","Epoch:   22 - Loss:  32.56, loss_sup:   24.5, loss_unsup:   12.0, w_t:  0.67\n","Epoch:   23 - Loss:  33.71, loss_sup:   24.4, loss_unsup:   11.9, w_t:  0.78\n","Epoch:   24 - Loss:  33.99, loss_sup:   23.5, loss_unsup:   11.7, w_t:  0.90\n","Epoch:   25 - Loss:  34.83, loss_sup:   23.2, loss_unsup:   11.5, w_t:  1.01\n","Epoch:   26 - Loss:  35.07, loss_sup:   22.8, loss_unsup:   10.9, w_t:  1.12\n","For training: accuracy-9%; IOU-42%\n","For validation: accuracy-84%; IOU-67%\n","Epoch:   27 - Loss:  35.48, loss_sup:   22.1, loss_unsup:   10.9, w_t:  1.23\n","Epoch:   28 - Loss:  37.46, loss_sup:   22.9, loss_unsup:   11.0, w_t:  1.32\n","Epoch:   29 - Loss:  37.56, loss_sup:   22.3, loss_unsup:   10.9, w_t:  1.40\n","Epoch:   30 - Loss:  37.24, loss_sup:   21.9, loss_unsup:   10.5, w_t:  1.45\n","Epoch:   31 - Loss:  37.07, loss_sup:   21.8, loss_unsup:   10.3, w_t:  1.49\n","For training: accuracy-9%; IOU-44%\n","For validation: accuracy-84%; IOU-68%\n","Epoch:   32 - Loss:  35.98, loss_sup:   20.9, loss_unsup:   10.0, w_t:  1.50\n","Epoch:   33 - Loss:  36.36, loss_sup:   20.6, loss_unsup:   10.5, w_t:  1.50\n","Epoch:   34 - Loss:  36.56, loss_sup:   20.7, loss_unsup:   10.6, w_t:  1.50\n","Epoch:   35 - Loss:  36.36, loss_sup:   20.4, loss_unsup:   10.6, w_t:  1.50\n","Epoch:   36 - Loss:  34.57, loss_sup:   19.6, loss_unsup:   10.0, w_t:  1.50\n","For training: accuracy-9%; IOU-45%\n","For validation: accuracy-84%; IOU-69%\n","Epoch:   37 - Loss:  36.18, loss_sup:   20.4, loss_unsup:   10.5, w_t:  1.50\n","Epoch:   38 - Loss:  34.67, loss_sup:   19.1, loss_unsup:   10.3, w_t:  1.50\n","Epoch:   39 - Loss:  33.34, loss_sup:   17.9, loss_unsup:   10.3, w_t:  1.50\n","Epoch:   40 - Loss:  33.50, loss_sup:   18.2, loss_unsup:   10.2, w_t:  1.50\n","Epoch:   41 - Loss:  34.03, loss_sup:   18.3, loss_unsup:   10.5, w_t:  1.50\n","For training: accuracy-9%; IOU-46%\n","For validation: accuracy-84%; IOU-69%\n","Epoch:   42 - Loss:  35.19, loss_sup:   19.2, loss_unsup:   10.7, w_t:  1.50\n","Epoch:   43 - Loss:  33.09, loss_sup:   17.5, loss_unsup:   10.4, w_t:  1.50\n","Epoch:   44 - Loss:  32.49, loss_sup:   17.1, loss_unsup:   10.2, w_t:  1.50\n","Epoch:   45 - Loss:  31.78, loss_sup:   16.4, loss_unsup:   10.2, w_t:  1.50\n","Epoch:   46 - Loss:  32.25, loss_sup:   16.7, loss_unsup:   10.4, w_t:  1.50\n","For training: accuracy-9%; IOU-45%\n","For validation: accuracy-85%; IOU-69%\n","Epoch:   47 - Loss:  32.51, loss_sup:   16.6, loss_unsup:   10.6, w_t:  1.50\n","Epoch:   48 - Loss:  31.01, loss_sup:   15.7, loss_unsup:   10.2, w_t:  1.50\n","Epoch:   49 - Loss:  31.03, loss_sup:   15.7, loss_unsup:   10.2, w_t:  1.50\n","Epoch:   50 - Loss:  31.28, loss_sup:   15.8, loss_unsup:   10.4, w_t:  1.50\n","Epoch:   51 - Loss:  31.24, loss_sup:   15.5, loss_unsup:   10.5, w_t:  1.50\n","For training: accuracy-9%; IOU-43%\n","For validation: accuracy-85%; IOU-69%\n","Epoch:   52 - Loss:  30.31, loss_sup:   15.0, loss_unsup:   10.2, w_t:  1.50\n","Epoch:   53 - Loss:  30.94, loss_sup:   15.2, loss_unsup:   10.5, w_t:  1.50\n","Epoch:   54 - Loss:  29.87, loss_sup:   14.3, loss_unsup:   10.4, w_t:  1.50\n","Epoch:   55 - Loss:  29.09, loss_sup:   13.9, loss_unsup:   10.1, w_t:  1.50\n","Epoch:   56 - Loss:  29.17, loss_sup:   13.6, loss_unsup:   10.4, w_t:  1.50\n","For training: accuracy-9%; IOU-43%\n","For validation: accuracy-85%; IOU-69%\n","Epoch:   57 - Loss:  28.16, loss_sup:   13.0, loss_unsup:   10.1, w_t:  1.50\n","Epoch:   58 - Loss:  27.92, loss_sup:   12.8, loss_unsup:   10.1, w_t:  1.50\n","Epoch:   59 - Loss:  28.40, loss_sup:   13.2, loss_unsup:   10.2, w_t:  1.50\n","Epoch:   60 - Loss:  28.48, loss_sup:   13.1, loss_unsup:   10.2, w_t:  1.50\n","Epoch:   61 - Loss:  28.55, loss_sup:   12.7, loss_unsup:   10.5, w_t:  1.50\n","For training: accuracy-9%; IOU-44%\n","For validation: accuracy-85%; IOU-69%\n","Epoch:   62 - Loss:  27.77, loss_sup:   12.4, loss_unsup:   10.2, w_t:  1.50\n","Epoch:   63 - Loss:  27.33, loss_sup:   12.3, loss_unsup:   10.0, w_t:  1.50\n","Epoch:   64 - Loss:  26.83, loss_sup:   12.2, loss_unsup:    9.8, w_t:  1.50\n","Epoch:   65 - Loss:  27.79, loss_sup:   12.0, loss_unsup:   10.5, w_t:  1.50\n","Epoch:   66 - Loss:  26.96, loss_sup:   11.8, loss_unsup:   10.1, w_t:  1.50\n","For training: accuracy-9%; IOU-42%\n","For validation: accuracy-85%; IOU-69%\n","Epoch:   67 - Loss:  27.35, loss_sup:   11.6, loss_unsup:   10.5, w_t:  1.50\n","Epoch:   68 - Loss:  26.25, loss_sup:   11.2, loss_unsup:   10.1, w_t:  1.50\n","Epoch:   69 - Loss:  26.13, loss_sup:   11.3, loss_unsup:    9.9, w_t:  1.50\n","Epoch:   70 - Loss:  26.31, loss_sup:   11.1, loss_unsup:   10.1, w_t:  1.50\n","Epoch:   71 - Loss:  25.90, loss_sup:   10.6, loss_unsup:   10.2, w_t:  1.50\n","For training: accuracy-9%; IOU-43%\n","For validation: accuracy-85%; IOU-70%\n","Epoch:   72 - Loss:  25.30, loss_sup:   10.4, loss_unsup:    9.9, w_t:  1.50\n","Epoch:   73 - Loss:  25.80, loss_sup:   10.7, loss_unsup:   10.1, w_t:  1.50\n","Epoch:   74 - Loss:  26.10, loss_sup:   10.6, loss_unsup:   10.4, w_t:  1.50\n","Epoch:   75 - Loss:  25.87, loss_sup:   10.6, loss_unsup:   10.2, w_t:  1.50\n","Epoch:   76 - Loss:  24.85, loss_sup:   10.3, loss_unsup:    9.7, w_t:  1.50\n","For training: accuracy-9%; IOU-42%\n","For validation: accuracy-85%; IOU-69%\n","Epoch:   77 - Loss:  24.16, loss_sup:    9.4, loss_unsup:    9.8, w_t:  1.50\n","Epoch:   78 - Loss:  24.95, loss_sup:   10.0, loss_unsup:   10.0, w_t:  1.50\n","Epoch:   79 - Loss:  24.29, loss_sup:    9.8, loss_unsup:    9.7, w_t:  1.50\n","Epoch:   80 - Loss:  24.91, loss_sup:   10.0, loss_unsup:   10.0, w_t:  1.50\n","Epoch:   81 - Loss:  23.83, loss_sup:    9.3, loss_unsup:    9.7, w_t:  1.50\n","For training: accuracy-9%; IOU-43%\n","For validation: accuracy-85%; IOU-70%\n","Epoch:   82 - Loss:  23.75, loss_sup:    9.3, loss_unsup:    9.7, w_t:  1.50\n","Epoch:   83 - Loss:  24.79, loss_sup:    9.7, loss_unsup:   10.0, w_t:  1.50\n","Epoch:   84 - Loss:  23.71, loss_sup:    9.1, loss_unsup:    9.7, w_t:  1.50\n","Epoch:   85 - Loss:  23.69, loss_sup:    9.0, loss_unsup:    9.8, w_t:  1.50\n","Epoch:   86 - Loss:  23.38, loss_sup:    9.0, loss_unsup:    9.6, w_t:  1.50\n","For training: accuracy-9%; IOU-42%\n","For validation: accuracy-85%; IOU-69%\n","Epoch:   87 - Loss:  23.01, loss_sup:    8.6, loss_unsup:    9.6, w_t:  1.50\n","Epoch:   88 - Loss:  22.05, loss_sup:    8.4, loss_unsup:    9.1, w_t:  1.50\n","Epoch:   89 - Loss:  23.44, loss_sup:    8.9, loss_unsup:    9.7, w_t:  1.50\n","Epoch:   90 - Loss:  24.72, loss_sup:    9.5, loss_unsup:   10.2, w_t:  1.50\n","Epoch:   91 - Loss:  23.67, loss_sup:    8.8, loss_unsup:    9.9, w_t:  1.50\n","For training: accuracy-9%; IOU-41%\n","For validation: accuracy-85%; IOU-68%\n","Epoch:   92 - Loss:  23.28, loss_sup:    8.7, loss_unsup:    9.7, w_t:  1.50\n","Epoch:   93 - Loss:  23.58, loss_sup:    8.9, loss_unsup:    9.8, w_t:  1.50\n","Epoch:   94 - Loss:  23.45, loss_sup:    8.7, loss_unsup:    9.8, w_t:  1.50\n","Epoch:   95 - Loss:  22.30, loss_sup:    8.2, loss_unsup:    9.4, w_t:  1.50\n","Epoch:   96 - Loss:  21.42, loss_sup:    7.8, loss_unsup:    9.1, w_t:  1.50\n","For training: accuracy-9%; IOU-41%\n","For validation: accuracy-85%; IOU-69%\n","Epoch:   97 - Loss:  22.08, loss_sup:    8.1, loss_unsup:    9.4, w_t:  1.50\n","Epoch:   98 - Loss:  21.05, loss_sup:    7.6, loss_unsup:    9.0, w_t:  1.50\n","Epoch:   99 - Loss:  20.88, loss_sup:    7.4, loss_unsup:    9.0, w_t:  1.50\n","Epoch:  100 - Loss:  21.03, loss_sup:    7.7, loss_unsup:    8.9, w_t:  1.50\n"]}],"source":["# Train\n","eval_freq = 5\n","losses, sup_losses, unsup_losses, accsTr, IousTr, accsVal, IousVal, wts = [], [], [], [], [], [], [] , []\n","\n","modelS.train() # Put model in train mode - important because we have dropout\n","\n","for epoch in range(epochs):\n","\n","        running_loss, running_loss_sup, running_loss_unsup = 0, 0, 0 # Init running losses\n","        w_t = wt(rampup_length=ramp_up, current=epoch, alpha=consistency, wait_period=wait_period) # Get unsupervised weight for the epoch\n","\n","        for step, data in enumerate(mixed_train_loader):\n","\n","            imgs, labs = data\n","            imgS_aug = augmentation(imgs) # Augment images\n","\n","            imgS_aug = imgS_aug.to(device)\n","            labs = labs.squeeze().type(torch.LongTensor).to(device)\n","\n","            optimizer.zero_grad()\n","\n","            # Forward pass for student and teacher\n","            z = modelS(imgS_aug) \n","\n","            sup_idx = torch.tensor([(elem != -1).item() for elem in labs[:, 0, 0]]).to(device) #If batchsize is the first dim\n","\n","            Ls = dice_loss(z[sup_idx], labs[sup_idx])\n","            Lu = unsup_loss(z, modelT, imgs, device)\n","            loss = Ls + w_t * Lu\n","            \n","            loss.backward()\n","            \n","            optimizer.step()    \n","            global_step += 1\n","            update_ema_variables(modelS, modelT, alpha, global_step)\n","            running_loss += loss.item()\n","            running_loss_sup += Ls.item()\n","            running_loss_unsup += Lu.item()\n","\n","        print(f'Epoch: {epoch + 1:4d} - Loss: {running_loss:6.2f}, loss_sup: {running_loss_sup:6.1f}, loss_unsup: {running_loss_unsup:6.1f}, w_t: {w_t: 3.2f}')\n","        losses.append(running_loss)\n","        sup_losses.append(running_loss_sup)\n","        unsup_losses.append(running_loss_unsup)\n","        wts.append(w_t)\n","\n","        if (epoch % eval_freq == 0):\n","\n","          # Get accuracy and IOU for train and validation dataset \n","          accTr, IouTr = evaluate_model(modelS, mixed_train_loader, device)\n","          accVal, IouVal = evaluate_model(modelS, val_loader, device)\n","\n","          accsTr.append(accTr)\n","          IousTr.append(IouTr)   \n","          accsVal.append(accVal)\n","          IousVal.append(IouVal)\n","\n","          print(f'For training: accuracy-{accTr:2.0%}; IOU-{IouTr:2.0%}')\n","          print(f'For validation: accuracy-{accVal:2.0%}; IOU-{IouVal:2.0%}')\n","\n","          np.savetxt(f\"{model_save_path}running_loss\", losses)\n","          np.savetxt(f\"{model_save_path}sup_loss\", sup_losses)\n","          np.savetxt(f\"{model_save_path}unsup_loss\", unsup_losses)\n","\n","          np.savetxt(f\"{model_save_path}train_acc\", accsTr)\n","          np.savetxt(f\"{model_save_path}train_IOU\", IousTr)\n","          np.savetxt(f\"{model_save_path}val_acc\", accsVal)\n","          np.savetxt(f\"{model_save_path}val_IOU\", IousVal)\n","\n","          np.savetxt(f\"{model_save_path}weights\", wts)\n","\n","          torch.save(modelS.state_dict(), f\"{model_save_path}student_epoch_{epoch+1}\" + '.pt')\n","\n","        #if (epoch+1)%8 == 0:\n","        #    scheduler.step()\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"JmzDe3cH-HbY"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"comp0197-cw1-pt","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"489908b824c0469a814b1045fbe3171d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ea5fd48d16c744f891b74cad147d8cea","IPY_MODEL_2f7fb90256384f3d8f1172d892a30c98","IPY_MODEL_da4f654b720844af93a5ffda5f0f5356"],"layout":"IPY_MODEL_6dcf94609a6443fc8f63746ed94941d0"}},"ea5fd48d16c744f891b74cad147d8cea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01381922ae1742cb8974b9ee84ab9bc0","placeholder":"​","style":"IPY_MODEL_cdcba8de401248ec8517c176bd81b800","value":"100%"}},"2f7fb90256384f3d8f1172d892a30c98":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_de1d885067194bdeb5481c59dc2b78a0","max":791918971,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55f201a860b541189e579883921e69b7","value":791918971}},"da4f654b720844af93a5ffda5f0f5356":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a1b2a4ae66e4c808ba8e589ff5c8230","placeholder":"​","style":"IPY_MODEL_1fdb99faf90346bdb45757c26a3c49ec","value":" 791918971/791918971 [00:56&lt;00:00, 14116471.35it/s]"}},"6dcf94609a6443fc8f63746ed94941d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01381922ae1742cb8974b9ee84ab9bc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdcba8de401248ec8517c176bd81b800":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de1d885067194bdeb5481c59dc2b78a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55f201a860b541189e579883921e69b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a1b2a4ae66e4c808ba8e589ff5c8230":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fdb99faf90346bdb45757c26a3c49ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0526b58d475744d48173d80b823096e6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b50ca076dba7469fa6ea62049dd7cd10","IPY_MODEL_353b848f6e844c4e912ac909efe3db64","IPY_MODEL_b8242c13ae4d465ab5f7000aa1cb408e"],"layout":"IPY_MODEL_9376170f4376498e90bdd6590ae6e70e"}},"b50ca076dba7469fa6ea62049dd7cd10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_018297eb68d94a479560dd836a4b2adb","placeholder":"​","style":"IPY_MODEL_ccac6470651345c9ae794d6252793778","value":"100%"}},"353b848f6e844c4e912ac909efe3db64":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7413d91d32684b8a96943ee10a07cacc","max":19173078,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5c4912d5a4cd4ac2931918246fbc3866","value":19173078}},"b8242c13ae4d465ab5f7000aa1cb408e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b92cb20477664400bad5580bde130c3e","placeholder":"​","style":"IPY_MODEL_c36db982e3194e1fbfb8d55929d8054f","value":" 19173078/19173078 [00:02&lt;00:00, 12041744.43it/s]"}},"9376170f4376498e90bdd6590ae6e70e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"018297eb68d94a479560dd836a4b2adb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccac6470651345c9ae794d6252793778":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7413d91d32684b8a96943ee10a07cacc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c4912d5a4cd4ac2931918246fbc3866":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b92cb20477664400bad5580bde130c3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c36db982e3194e1fbfb8d55929d8054f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}